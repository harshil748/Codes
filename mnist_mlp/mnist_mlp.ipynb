{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f310821",
   "metadata": {},
   "source": [
    "# MNIST Handwritten Digit Recognition (MLP in PyTorch)\n",
    "\n",
    "This notebook trains a Multi-Layer Perceptron (MLP) on the MNIST dataset and walks through data loading, preprocessing, model construction, training, evaluation, visualization, saving/loading checkpoints, and an optional lightweight hyperparameter sweep.\n",
    "\n",
    "Sections mirror a production workflow and include optional mixed precision and hyperparameter exploration.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4174bae5",
   "metadata": {},
   "source": [
    "## 1. Install / Verify Dependencies\n",
    "\n",
    "If running in a fresh environment, you can (optionally) install required packages. This cell is idempotent and will skip installs if already present.\n",
    "\n",
    "```bash\n",
    "# Optional (uncomment if needed)\n",
    "# pip install torch torchvision torchaudio matplotlib seaborn scikit-learn tqdm\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d38332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) quick dependency check\n",
    "import importlib, sys\n",
    "\n",
    "required = [\"torch\", \"torchvision\", \"matplotlib\", \"seaborn\", \"sklearn\", \"tqdm\"]\n",
    "missing = []\n",
    "for pkg in required:\n",
    "    if importlib.util.find_spec(pkg) is None:\n",
    "        missing.append(pkg)\n",
    "print(\"Missing packages:\", missing if missing else \"None. All good.\")\n",
    "if missing:\n",
    "    print(\"You can install them with: pip install \" + \" \".join(missing))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db8b82c",
   "metadata": {},
   "source": [
    "## 2. Imports & Device Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb0eb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, math, json, time, random, pathlib\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Device selection: prefer CUDA, then MPS (Apple Silicon), else CPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc36ae1c",
   "metadata": {},
   "source": [
    "## 3. Reproducibility (Set All Random Seeds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e07ddbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "# Optional stricter determinism (may slow training)\n",
    "# torch.use_deterministic_algorithms(True)\n",
    "print(\"Seeds set to\", seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35aa9ab0",
   "metadata": {},
   "source": [
    "## 4. Hyperparameter Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a385a8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    \"batch_size\": 128,\n",
    "    \"epochs\": 10,\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"weight_decay\": 0.0,\n",
    "    \"hidden_sizes\": [256, 128],\n",
    "    \"input_dim\": 28 * 28,\n",
    "    \"num_classes\": 10,\n",
    "    \"scheduler_patience\": 3,\n",
    "    \"scheduler_factor\": 0.5,\n",
    "    \"num_workers\": 2,\n",
    "    \"amp\": True,  # set False to disable mixed precision\n",
    "}\n",
    "print(hparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ff26d7",
   "metadata": {},
   "source": [
    "## 5. Define Data Transforms & Download MNIST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0d1fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    ")\n",
    "\n",
    "data_root = Path(\"./data\")\n",
    "train_dataset_full = datasets.MNIST(\n",
    "    root=data_root, train=True, download=True, transform=transform\n",
    ")\n",
    "test_dataset = datasets.MNIST(\n",
    "    root=data_root, train=False, download=True, transform=transform\n",
    ")\n",
    "print(\"Train size (raw):\", len(train_dataset_full), \" Test size:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ce3df9",
   "metadata": {},
   "source": [
    "## 6. Create DataLoaders (Train / Val / Test Split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a4d378",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size = 5000\n",
    "train_size = len(train_dataset_full) - val_size\n",
    "train_dataset, val_dataset = random_split(train_dataset_full, [train_size, val_size])\n",
    "\n",
    "kwargs = {\n",
    "    \"batch_size\": hparams[\"batch_size\"],\n",
    "    \"num_workers\": hparams[\"num_workers\"],\n",
    "    \"pin_memory\": True if device.type == \"cuda\" else False,\n",
    "}\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, **kwargs)\n",
    "val_loader = DataLoader(val_dataset, shuffle=False, **kwargs)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, **kwargs)\n",
    "print(\n",
    "    f\"Train: {len(train_dataset)}  Val: {len(val_dataset)}  Test: {len(test_dataset)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5044da9d",
   "metadata": {},
   "source": [
    "## 7. Define MLP Model Class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1caa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_sizes, num_classes):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev = input_dim\n",
    "        for h in hidden_sizes:\n",
    "            layers.append(nn.Linear(prev, h))\n",
    "            layers.append(nn.ReLU())\n",
    "            prev = h\n",
    "        layers.append(nn.Linear(prev, num_classes))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "model = MLP(hparams[\"input_dim\"], hparams[\"hidden_sizes\"], hparams[\"num_classes\"]).to(\n",
    "    device\n",
    ")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d41c557",
   "metadata": {},
   "source": [
    "## 8. Utility: Count & Display Trainable Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6072c484",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_params(model):\n",
    "    total = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    if total >= 1e6:\n",
    "        human = f\"{total/1e6:.2f}M\"\n",
    "    elif total >= 1e3:\n",
    "        human = f\"{total/1e3:.1f}K\"\n",
    "    else:\n",
    "        human = str(total)\n",
    "    print(f\"Trainable parameters: {human} ({total})\")\n",
    "\n",
    "\n",
    "count_params(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8d9161",
   "metadata": {},
   "source": [
    "## 9. Initialize Model, Loss Function, Optimizer, Scheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e253788e",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=hparams[\"learning_rate\"],\n",
    "    weight_decay=hparams[\"weight_decay\"],\n",
    ")\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode=\"min\",\n",
    "    factor=hparams[\"scheduler_factor\"],\n",
    "    patience=hparams[\"scheduler_patience\"],\n",
    ")\n",
    "print(\"Optimizer and scheduler initialized\")\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(device.type == \"cuda\" and hparams[\"amp\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fef406",
   "metadata": {},
   "source": [
    "## 10. Training Step Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949ec404",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, optimizer, device, scaler=None):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    pbar = tqdm(dataloader, leave=False)\n",
    "    for images, labels in pbar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.cuda.amp.autocast(\n",
    "            enabled=(scaler is not None and scaler.is_enabled())\n",
    "        ):\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "        if scaler is not None and scaler.is_enabled():\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        pbar.set_description(f\"loss {loss.item():.4f}\")\n",
    "    avg_loss = running_loss / total\n",
    "    acc = correct / total\n",
    "    return avg_loss, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defdb94a",
   "metadata": {},
   "source": [
    "## 11. Evaluation Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0053e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, device, return_preds=False):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            if return_preds:\n",
    "                all_preds.append(preds.cpu())\n",
    "                all_labels.append(labels.cpu())\n",
    "    avg_loss = running_loss / total\n",
    "    acc = correct / total\n",
    "    if return_preds:\n",
    "        return avg_loss, acc, torch.cat(all_preds), torch.cat(all_labels)\n",
    "    return avg_loss, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d99b10",
   "metadata": {},
   "source": [
    "## 12. Main Training Loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f75d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {\n",
    "    \"epoch\": [],\n",
    "    \"train_loss\": [],\n",
    "    \"val_loss\": [],\n",
    "    \"train_acc\": [],\n",
    "    \"val_acc\": [],\n",
    "    \"lr\": [],\n",
    "}\n",
    "best_val_acc = 0.0\n",
    "best_state = None\n",
    "start_time = time.time()\n",
    "for epoch in range(1, hparams[\"epochs\"] + 1):\n",
    "    train_loss, train_acc = train_one_epoch(\n",
    "        model, train_loader, optimizer, device, scaler\n",
    "    )\n",
    "    val_loss, val_acc = evaluate(model, val_loader, device)\n",
    "    scheduler.step(val_loss)\n",
    "    current_lr = optimizer.param_groups[0][\"lr\"]\n",
    "    history[\"epoch\"].append(epoch)\n",
    "    history[\"train_loss\"].append(train_loss)\n",
    "    history[\"val_loss\"].append(val_loss)\n",
    "    history[\"train_acc\"].append(train_acc)\n",
    "    history[\"val_acc\"].append(val_acc)\n",
    "    history[\"lr\"].append(current_lr)\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_state = model.state_dict()\n",
    "    print(\n",
    "        f\"Epoch {epoch:02d}/{hparams['epochs']} | TLoss {train_loss:.4f} VLoss {val_loss:.4f} | TAcc {train_acc*100:.2f}% VAcc {val_acc*100:.2f}% | LR {current_lr:.2e}\"\n",
    "    )\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(\n",
    "    f\"Training completed in {total_time/60:.2f} minutes. Best Val Acc: {best_val_acc*100:.2f}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38368f97",
   "metadata": {},
   "source": [
    "## 13. Track & Store Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3442bd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metrics to JSON\n",
    "metrics_path = Path(\"training_metrics.json\")\n",
    "with open(metrics_path, \"w\") as f:\n",
    "    json.dump(history, f, indent=2)\n",
    "print(\"Metrics saved to\", metrics_path.resolve())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b69d67",
   "metadata": {},
   "source": [
    "## 14. Plot Training vs Validation Curves\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02c30f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history[\"epoch\"], history[\"train_loss\"], label=\"Train Loss\")\n",
    "plt.plot(history[\"epoch\"], history[\"val_loss\"], label=\"Val Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history[\"epoch\"], history[\"train_acc\"], label=\"Train Acc\")\n",
    "plt.plot(history[\"epoch\"], history[\"val_acc\"], label=\"Val Acc\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d39651",
   "metadata": {},
   "source": [
    "## 15. Final Test Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608ef80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best weights\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)\n",
    "\n",
    "test_loss, test_acc, test_preds, test_labels = evaluate(\n",
    "    model, test_loader, device, return_preds=True\n",
    ")\n",
    "print(f\"Test Loss: {test_loss:.4f}  Test Accuracy: {test_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630cc76b",
   "metadata": {},
   "source": [
    "## 16. Confusion Matrix & Classification Report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8352f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(test_labels, test_preds)\n",
    "report = classification_report(test_labels, test_preds, digits=4)\n",
    "print(report)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82812194",
   "metadata": {},
   "source": [
    "## 17. Visualize Sample Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1130431c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "examples = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        for img, pred, label in zip(images, preds, labels):\n",
    "            examples.append((img.cpu(), pred.item(), label.item()))\n",
    "            if len(examples) >= 36:\n",
    "                break\n",
    "        if len(examples) >= 36:\n",
    "            break\n",
    "\n",
    "cols = 6\n",
    "rows = math.ceil(len(examples) / cols)\n",
    "plt.figure(figsize=(cols * 1.5, rows * 1.5))\n",
    "for i, (img, pred, label) in enumerate(examples):\n",
    "    plt.subplot(rows, cols, i + 1)\n",
    "    plt.imshow(img.squeeze(0), cmap=\"gray\")\n",
    "    color = \"green\" if pred == label else \"red\"\n",
    "    plt.title(f\"p:{pred} t:{label}\", color=color, fontsize=8)\n",
    "    plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006280fb",
   "metadata": {},
   "source": [
    "## 18. Save Model Checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e3ef11",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = {\n",
    "    \"model_state\": best_state if best_state is not None else model.state_dict(),\n",
    "    \"hyperparameters\": hparams,\n",
    "    \"best_val_acc\": best_val_acc,\n",
    "    \"test_acc\": float(test_acc),\n",
    "    \"metrics\": history,\n",
    "}\n",
    "ckpt_path = Path(\"mnist_mlp.pt\")\n",
    "torch.save(ckpt, ckpt_path)\n",
    "print(\"Checkpoint saved to\", ckpt_path.resolve())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc5e6ab",
   "metadata": {},
   "source": [
    "## 19. Load Checkpoint & Inference Sanity Check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e1676c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = torch.load(\"mnist_mlp.pt\", map_location=device)\n",
    "model2 = MLP(hparams[\"input_dim\"], hparams[\"hidden_sizes\"], hparams[\"num_classes\"]).to(\n",
    "    device\n",
    ")\n",
    "model2.load_state_dict(loaded[\"model_state\"])\n",
    "model2.eval()\n",
    "with torch.no_grad():\n",
    "    images, labels = next(iter(test_loader))\n",
    "    images = images.to(device)\n",
    "    outputs = model2(images)\n",
    "    preds = outputs.argmax(dim=1)\n",
    "print(\n",
    "    \"Sanity batch accuracy:\", (preds.cpu() == labels).float().mean().item() * 100, \"%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfc48dc",
   "metadata": {},
   "source": [
    "## 20. Optional: Simple Hyperparameter Sweep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82cc07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "enable_sweep = False  # set True to run a quick sweep (will take extra time)\n",
    "sweep_results = []\n",
    "\n",
    "if enable_sweep:\n",
    "    sweep_configs = [[512, 256, 128], [256, 256, 128], [512, 256], [128, 64]]\n",
    "    short_epochs = 3\n",
    "    for cfg in sweep_configs:\n",
    "        temp_model = MLP(hparams[\"input_dim\"], cfg, hparams[\"num_classes\"]).to(device)\n",
    "        temp_opt = optim.Adam(temp_model.parameters(), lr=1e-3)\n",
    "        for ep in range(short_epochs):\n",
    "            train_one_epoch(temp_model, train_loader, temp_opt, device)\n",
    "            _, val_acc = evaluate(temp_model, val_loader, device)\n",
    "        sweep_results.append({\"hidden\": cfg, \"val_acc\": val_acc})\n",
    "    print(\"Sweep results:\")\n",
    "    for r in sweep_results:\n",
    "        print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb551d90",
   "metadata": {},
   "source": [
    "## 21. Optional: Mixed Precision Note\n",
    "\n",
    "Mixed precision (autocast + GradScaler) is enabled automatically when on CUDA and `hparams['amp']` is True. Adjust if numerical instability occurs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f945ff36",
   "metadata": {},
   "source": [
    "## 22. (Optional) Export Notebook to Script\n",
    "\n",
    "```bash\n",
    "# Run this in a shell cell if you want a .py export\n",
    "# !jupyter nbconvert --to script mnist_mlp.ipynb\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c8efa4",
   "metadata": {},
   "source": [
    "## 23. Environment Info & Cleanup\n",
    "\n",
    "Below we print versions and (if on CUDA) optionally clear GPU cache.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4df923a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"Device:\", device)\n",
    "if device.type == \"cuda\":\n",
    "    print(\"CUDA device count:\", torch.cuda.device_count())\n",
    "    print(\"Current device name:\", torch.cuda.get_device_name(0))\n",
    "    torch.cuda.empty_cache()\n",
    "elif device.type == \"mps\":\n",
    "    print(\"Using Apple Silicon MPS backend\")\n",
    "else:\n",
    "    print(\"Running on CPU\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
