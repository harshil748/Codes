{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9558c41d",
   "metadata": {},
   "source": [
    "# Smart Product Pricing Challenge — Full Pipeline\n",
    "\n",
    "This notebook contains an end-to-end pipeline: EDA, feature engineering (text + image), model training, CV (SMAPE), and submission generation.\n",
    "\n",
    "Run cells sequentially. Adjust `IMAGE_SAMPLE_LIMIT`, `TFIDF_MAX_FEATURES`, and other config values before running heavy cells.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf20349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config variables set.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "ZIP_PATH = \"/Users/harshilpatel/CODE/Student Resource.zip\"\n",
    "EXTRACT_DIR = \"/Users/harshilpatel/CODE/student_resource_extracted\"\n",
    "OUTPUT_SUBMISSION = \"/Users/harshilpatel/CODE/test_out_full.csv\"\n",
    "IMAGE_SAMPLE_LIMIT = 2000\n",
    "TFIDF_MAX_FEATURES = 10000\n",
    "print(\"Config variables set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfd4690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted to /Users/harshilpatel/CODE/student_resource_extracted\n",
      "train: /Users/harshilpatel/CODE/student_resource_extracted/student_resource/dataset/train.csv\n",
      "test : /Users/harshilpatel/CODE/student_resource_extracted/student_resource/dataset/test.csv\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "if os.path.exists(ZIP_PATH):\n",
    "    with zipfile.ZipFile(ZIP_PATH, \"r\") as z:\n",
    "        z.extractall(EXTRACT_DIR)\n",
    "    print(\"Extracted to\", EXTRACT_DIR)\n",
    "else:\n",
    "    print(\"ZIP not found at\", ZIP_PATH)\n",
    "\n",
    "# locate CSVs\n",
    "train_path = None\n",
    "test_path = None\n",
    "for root, dirs, files in os.walk(EXTRACT_DIR):\n",
    "    for f in files:\n",
    "        if f.lower().startswith(\"train\") and f.lower().endswith(\".csv\"):\n",
    "            train_path = os.path.join(root, f)\n",
    "        if f.lower().startswith(\"test\") and f.lower().endswith(\".csv\"):\n",
    "            test_path = os.path.join(root, f)\n",
    "print(\"train:\", train_path)\n",
    "print(\"test :\", test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca3f332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded train/test rows: 75000 75000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>catalog_content</th>\n",
       "      <th>image_link</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33127</td>\n",
       "      <td>Item Name: La Victoria Green Taco Sauce Mild, ...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/51mo8htwTH...</td>\n",
       "      <td>4.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>198967</td>\n",
       "      <td>Item Name: Salerno Cookies, The Original Butte...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71YtriIHAA...</td>\n",
       "      <td>13.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>261251</td>\n",
       "      <td>Item Name: Bear Creek Hearty Soup Bowl, Creamy...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/51+PFEe-w-...</td>\n",
       "      <td>1.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55858</td>\n",
       "      <td>Item Name: Judee’s Blue Cheese Powder 11.25 oz...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/41mu0HAToD...</td>\n",
       "      <td>30.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>292686</td>\n",
       "      <td>Item Name: kedem Sherry Cooking Wine, 12.7 Oun...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/41sA037+Qv...</td>\n",
       "      <td>66.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_id                                    catalog_content  \\\n",
       "0      33127  Item Name: La Victoria Green Taco Sauce Mild, ...   \n",
       "1     198967  Item Name: Salerno Cookies, The Original Butte...   \n",
       "2     261251  Item Name: Bear Creek Hearty Soup Bowl, Creamy...   \n",
       "3      55858  Item Name: Judee’s Blue Cheese Powder 11.25 oz...   \n",
       "4     292686  Item Name: kedem Sherry Cooking Wine, 12.7 Oun...   \n",
       "\n",
       "                                          image_link  price  \n",
       "0  https://m.media-amazon.com/images/I/51mo8htwTH...   4.89  \n",
       "1  https://m.media-amazon.com/images/I/71YtriIHAA...  13.12  \n",
       "2  https://m.media-amazon.com/images/I/51+PFEe-w-...   1.97  \n",
       "3  https://m.media-amazon.com/images/I/41mu0HAToD...  30.34  \n",
       "4  https://m.media-amazon.com/images/I/41sA037+Qv...  66.49  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(train_path)\n",
    "test = pd.read_csv(test_path)\n",
    "print(\"Loaded train/test rows:\", len(train), len(test))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067e3df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['sample_id', 'catalog_content', 'image_link', 'price']\n",
      "Missing (train):\n",
      "sample_id          0\n",
      "catalog_content    0\n",
      "image_link         0\n",
      "price              0\n",
      "dtype: int64\n",
      "Price stats:\n",
      "count    75000.000000\n",
      "mean        23.647654\n",
      "std         33.376932\n",
      "min          0.130000\n",
      "25%          6.795000\n",
      "50%         14.000000\n",
      "75%         28.625000\n",
      "max       2796.000000\n",
      "Name: price, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns:\", train.columns.tolist())\n",
    "print(\"Missing (train):\")\n",
    "print(train.isnull().sum())\n",
    "print(\"Price stats:\")\n",
    "print(train[\"price\"].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe7f038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ipq_raw\n",
       "1          3975\n",
       "12         2690\n",
       "6          2663\n",
       "2          2064\n",
       "2 Pack     1854\n",
       "5 oz       1791\n",
       "4          1706\n",
       "5          1678\n",
       "3 Pack     1504\n",
       "3          1461\n",
       "0          1305\n",
       "8 oz       1285\n",
       "8          1188\n",
       "16 oz       986\n",
       "16          927\n",
       "12 oz       892\n",
       "4 oz        887\n",
       "12 Pack     791\n",
       "10          772\n",
       "24          760\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def extract_ipq(text):\n",
    "    if not isinstance(text, str):\n",
    "        return np.nan\n",
    "    patterns = [\n",
    "        r\"(\\b\\d+\\s*(?:pcs|pieces|count|ct|pk|pack)\\b)\",\n",
    "        r\"(\\b\\d+\\s*(?:x|X)\\s*\\d*\\b)\",\n",
    "        r\"(\\b\\d+\\s*(?:ml|l|g|kg|gm|oz)\\b)\",\n",
    "    ]\n",
    "    for p in patterns:\n",
    "        m = re.search(p, text, flags=re.IGNORECASE)\n",
    "        if m:\n",
    "            return m.group(0)\n",
    "    m2 = re.search(r\"(\\b\\d+\\b)(?!.*\\b\\d+\\b)\", text)\n",
    "    if m2:\n",
    "        return m2.group(0)\n",
    "    return np.nan\n",
    "\n",
    "\n",
    "train[\"ipq_raw\"] = train[\"catalog_content\"].apply(extract_ipq)\n",
    "test[\"ipq_raw\"] = test[\"catalog_content\"].apply(extract_ipq)\n",
    "train[\"ipq_raw\"].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8949eb6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF shapes: (75000, 10000) (75000, 10000)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def clean_text(s):\n",
    "    if not isinstance(s, str):\n",
    "        return \"\"\n",
    "    s = s.lower()\n",
    "    s = re.sub(r\"http\\S+\", \" \", s)\n",
    "    s = re.sub(r\"[^a-z0-9\\s]\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "\n",
    "train[\"catalog_clean\"] = train[\"catalog_content\"].apply(clean_text)\n",
    "test[\"catalog_clean\"] = test[\"catalog_content\"].apply(clean_text)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=TFIDF_MAX_FEATURES, ngram_range=(1, 2))\n",
    "vectorizer.fit(pd.concat([train[\"catalog_clean\"], test[\"catalog_clean\"]]))\n",
    "X_text_train = vectorizer.transform(train[\"catalog_clean\"])\n",
    "X_text_test = vectorizer.transform(test[\"catalog_clean\"])\n",
    "print(\"TF-IDF shapes:\", X_text_train.shape, X_text_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9335e35a",
   "metadata": {},
   "source": [
    "### Optional: sentence-transformers embeddings\n",
    "\n",
    "This cell will install and compute sentence-transformer embeddings. It may be slow and requires internet. If offline, skip this cell or load a local model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cdddee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea96a71f330c408cb8e7441c959876dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1172 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example (do not run if offline):\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "emb_train = model.encode(\n",
    "    train[\"catalog_clean\"].tolist(), batch_size=64, show_progress_bar=True\n",
    ")\n",
    "# Save or subsample embeddings for modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29034967",
   "metadata": {},
   "source": [
    "### Image download and basic features\n",
    "\n",
    "Download images with retry logic. Compute width, height, aspect, mean pixel. Then compute CNN embeddings using ResNet50 (torchvision).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f6ac1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>aspect</th>\n",
       "      <th>mean_px</th>\n",
       "      <th>url</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>234.657214</td>\n",
       "      <td>https://m.media-amazon.com/images/I/51mo8htwTH...</td>\n",
       "      <td>/Users/harshilpatel/CODE/student_resource_extr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1200</td>\n",
       "      <td>1200</td>\n",
       "      <td>1.0</td>\n",
       "      <td>171.139793</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71YtriIHAA...</td>\n",
       "      <td>/Users/harshilpatel/CODE/student_resource_extr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>174.827907</td>\n",
       "      <td>https://m.media-amazon.com/images/I/51+PFEe-w-...</td>\n",
       "      <td>/Users/harshilpatel/CODE/student_resource_extr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>205.804781</td>\n",
       "      <td>https://m.media-amazon.com/images/I/41mu0HAToD...</td>\n",
       "      <td>/Users/harshilpatel/CODE/student_resource_extr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>222.876347</td>\n",
       "      <td>https://m.media-amazon.com/images/I/41sA037+Qv...</td>\n",
       "      <td>/Users/harshilpatel/CODE/student_resource_extr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   width  height  aspect     mean_px  \\\n",
       "0   1000    1000     1.0  234.657214   \n",
       "1   1200    1200     1.0  171.139793   \n",
       "2    500     500     1.0  174.827907   \n",
       "3    500     500     1.0  205.804781   \n",
       "4   1000    1000     1.0  222.876347   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://m.media-amazon.com/images/I/51mo8htwTH...   \n",
       "1  https://m.media-amazon.com/images/I/71YtriIHAA...   \n",
       "2  https://m.media-amazon.com/images/I/51+PFEe-w-...   \n",
       "3  https://m.media-amazon.com/images/I/41mu0HAToD...   \n",
       "4  https://m.media-amazon.com/images/I/41sA037+Qv...   \n",
       "\n",
       "                                                file  \n",
       "0  /Users/harshilpatel/CODE/student_resource_extr...  \n",
       "1  /Users/harshilpatel/CODE/student_resource_extr...  \n",
       "2  /Users/harshilpatel/CODE/student_resource_extr...  \n",
       "3  /Users/harshilpatel/CODE/student_resource_extr...  \n",
       "4  /Users/harshilpatel/CODE/student_resource_extr...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "IMG_DIR = os.path.join(EXTRACT_DIR, \"images\")\n",
    "os.makedirs(IMG_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "def download_image(url, dest, retries=2):\n",
    "    for i in range(retries + 1):\n",
    "        try:\n",
    "            r = requests.get(url, timeout=8)\n",
    "            if r.status_code == 200:\n",
    "                with open(dest, \"wb\") as f:\n",
    "                    f.write(r.content)\n",
    "                return True\n",
    "        except Exception:\n",
    "            time.sleep(0.5)\n",
    "    return False\n",
    "\n",
    "\n",
    "def image_stats(path):\n",
    "    try:\n",
    "        with Image.open(path) as im:\n",
    "            w, h = im.size\n",
    "            arr = np.array(im.convert(\"RGB\"))\n",
    "            return {\n",
    "                \"width\": w,\n",
    "                \"height\": h,\n",
    "                \"aspect\": float(w) / h if h else np.nan,\n",
    "                \"mean_px\": float(arr.mean()),\n",
    "            }\n",
    "    except Exception:\n",
    "        return {\"width\": np.nan, \"height\": np.nan, \"aspect\": np.nan, \"mean_px\": np.nan}\n",
    "\n",
    "\n",
    "# Download sample\n",
    "links = train[\"image_link\"].drop_duplicates().tolist()[:IMAGE_SAMPLE_LIMIT]\n",
    "img_meta = []\n",
    "for i, url in enumerate(links):\n",
    "    dest = os.path.join(IMG_DIR, f\"image_{i}.jpg\")\n",
    "    ok = download_image(url, dest)\n",
    "    if ok:\n",
    "        s = image_stats(dest)\n",
    "        s.update({\"url\": url, \"file\": dest})\n",
    "        img_meta.append(s)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "img_df = pd.DataFrame(img_meta)\n",
    "img_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef7f72b",
   "metadata": {},
   "source": [
    "### Image embeddings using ResNet50 (PyTorch)\n",
    "\n",
    "This cell will install torch if needed and compute embeddings. Run on GPU for speed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58945954",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harshilpatel/CODE/.venv-1/lib/python3.13/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/harshilpatel/CODE/.venv-1/lib/python3.13/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emb_0</th>\n",
       "      <th>emb_1</th>\n",
       "      <th>emb_2</th>\n",
       "      <th>emb_3</th>\n",
       "      <th>emb_4</th>\n",
       "      <th>emb_5</th>\n",
       "      <th>emb_6</th>\n",
       "      <th>emb_7</th>\n",
       "      <th>emb_8</th>\n",
       "      <th>emb_9</th>\n",
       "      <th>...</th>\n",
       "      <th>emb_2039</th>\n",
       "      <th>emb_2040</th>\n",
       "      <th>emb_2041</th>\n",
       "      <th>emb_2042</th>\n",
       "      <th>emb_2043</th>\n",
       "      <th>emb_2044</th>\n",
       "      <th>emb_2045</th>\n",
       "      <th>emb_2046</th>\n",
       "      <th>emb_2047</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.844571</td>\n",
       "      <td>1.227987</td>\n",
       "      <td>0.025293</td>\n",
       "      <td>0.002584</td>\n",
       "      <td>0.237795</td>\n",
       "      <td>1.381954</td>\n",
       "      <td>0.293015</td>\n",
       "      <td>0.034165</td>\n",
       "      <td>0.160291</td>\n",
       "      <td>0.098058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.508130</td>\n",
       "      <td>0.274645</td>\n",
       "      <td>0.142530</td>\n",
       "      <td>0.056105</td>\n",
       "      <td>0.018445</td>\n",
       "      <td>0.220828</td>\n",
       "      <td>0.016182</td>\n",
       "      <td>0.369143</td>\n",
       "      <td>0.275119</td>\n",
       "      <td>https://m.media-amazon.com/images/I/51mo8htwTH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.110833</td>\n",
       "      <td>1.911485</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.008957</td>\n",
       "      <td>0.811973</td>\n",
       "      <td>0.044334</td>\n",
       "      <td>0.249721</td>\n",
       "      <td>0.014019</td>\n",
       "      <td>0.286661</td>\n",
       "      <td>0.080281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.281596</td>\n",
       "      <td>0.586324</td>\n",
       "      <td>0.040830</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061991</td>\n",
       "      <td>0.052233</td>\n",
       "      <td>0.250995</td>\n",
       "      <td>0.002550</td>\n",
       "      <td>0.198911</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71YtriIHAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.554837</td>\n",
       "      <td>0.463608</td>\n",
       "      <td>0.228232</td>\n",
       "      <td>0.179348</td>\n",
       "      <td>1.114330</td>\n",
       "      <td>0.471750</td>\n",
       "      <td>0.371559</td>\n",
       "      <td>0.214669</td>\n",
       "      <td>0.426190</td>\n",
       "      <td>0.074604</td>\n",
       "      <td>...</td>\n",
       "      <td>0.263382</td>\n",
       "      <td>0.827038</td>\n",
       "      <td>0.054977</td>\n",
       "      <td>0.268808</td>\n",
       "      <td>0.146072</td>\n",
       "      <td>0.644417</td>\n",
       "      <td>0.318873</td>\n",
       "      <td>0.316151</td>\n",
       "      <td>0.465631</td>\n",
       "      <td>https://m.media-amazon.com/images/I/51+PFEe-w-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.725837</td>\n",
       "      <td>1.186047</td>\n",
       "      <td>0.348569</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693171</td>\n",
       "      <td>0.340718</td>\n",
       "      <td>0.795682</td>\n",
       "      <td>1.043030</td>\n",
       "      <td>0.670529</td>\n",
       "      <td>0.058493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.332458</td>\n",
       "      <td>0.719062</td>\n",
       "      <td>0.095259</td>\n",
       "      <td>0.158660</td>\n",
       "      <td>0.021819</td>\n",
       "      <td>0.267496</td>\n",
       "      <td>0.080402</td>\n",
       "      <td>0.356998</td>\n",
       "      <td>0.812485</td>\n",
       "      <td>https://m.media-amazon.com/images/I/41mu0HAToD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.365849</td>\n",
       "      <td>1.481238</td>\n",
       "      <td>0.382430</td>\n",
       "      <td>0.028895</td>\n",
       "      <td>0.238223</td>\n",
       "      <td>1.978534</td>\n",
       "      <td>0.431884</td>\n",
       "      <td>0.068905</td>\n",
       "      <td>0.006629</td>\n",
       "      <td>0.090226</td>\n",
       "      <td>...</td>\n",
       "      <td>0.570752</td>\n",
       "      <td>0.333824</td>\n",
       "      <td>0.056835</td>\n",
       "      <td>0.125275</td>\n",
       "      <td>0.001117</td>\n",
       "      <td>0.075989</td>\n",
       "      <td>0.054212</td>\n",
       "      <td>0.629280</td>\n",
       "      <td>0.018297</td>\n",
       "      <td>https://m.media-amazon.com/images/I/41sA037+Qv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2049 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      emb_0     emb_1     emb_2     emb_3     emb_4     emb_5     emb_6  \\\n",
       "0  0.844571  1.227987  0.025293  0.002584  0.237795  1.381954  0.293015   \n",
       "1  0.110833  1.911485  0.000412  0.008957  0.811973  0.044334  0.249721   \n",
       "2  0.554837  0.463608  0.228232  0.179348  1.114330  0.471750  0.371559   \n",
       "3  0.725837  1.186047  0.348569  0.000000  0.693171  0.340718  0.795682   \n",
       "4  0.365849  1.481238  0.382430  0.028895  0.238223  1.978534  0.431884   \n",
       "\n",
       "      emb_7     emb_8     emb_9  ...  emb_2039  emb_2040  emb_2041  emb_2042  \\\n",
       "0  0.034165  0.160291  0.098058  ...  0.508130  0.274645  0.142530  0.056105   \n",
       "1  0.014019  0.286661  0.080281  ...  0.281596  0.586324  0.040830  0.000000   \n",
       "2  0.214669  0.426190  0.074604  ...  0.263382  0.827038  0.054977  0.268808   \n",
       "3  1.043030  0.670529  0.058493  ...  0.332458  0.719062  0.095259  0.158660   \n",
       "4  0.068905  0.006629  0.090226  ...  0.570752  0.333824  0.056835  0.125275   \n",
       "\n",
       "   emb_2043  emb_2044  emb_2045  emb_2046  emb_2047  \\\n",
       "0  0.018445  0.220828  0.016182  0.369143  0.275119   \n",
       "1  0.061991  0.052233  0.250995  0.002550  0.198911   \n",
       "2  0.146072  0.644417  0.318873  0.316151  0.465631   \n",
       "3  0.021819  0.267496  0.080402  0.356998  0.812485   \n",
       "4  0.001117  0.075989  0.054212  0.629280  0.018297   \n",
       "\n",
       "                                                 url  \n",
       "0  https://m.media-amazon.com/images/I/51mo8htwTH...  \n",
       "1  https://m.media-amazon.com/images/I/71YtriIHAA...  \n",
       "2  https://m.media-amazon.com/images/I/51+PFEe-w-...  \n",
       "3  https://m.media-amazon.com/images/I/41mu0HAToD...  \n",
       "4  https://m.media-amazon.com/images/I/41sA037+Qv...  \n",
       "\n",
       "[5 rows x 2049 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import models, transforms\n",
    "\n",
    "resnet = models.resnet50(pretrained=True)\n",
    "resnet = torch.nn.Sequential(*list(resnet.children())[:-1]).eval()\n",
    "# define transforms\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# compute embeddings for img_df['file']\n",
    "embs = []\n",
    "for path in img_df[\"file\"].tolist():\n",
    "    try:\n",
    "        im = Image.open(path).convert(\"RGB\")\n",
    "        x = transform(im).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            out = resnet(x)\n",
    "        embs.append(out.cpu().numpy().reshape(-1))\n",
    "    except Exception:\n",
    "        embs.append(np.full((2048,), np.nan))\n",
    "\n",
    "# convert to DataFrame\n",
    "import numpy as np\n",
    "\n",
    "emb_arr = np.stack(embs)\n",
    "emb_df = pd.DataFrame(emb_arr, columns=[f\"emb_{i}\" for i in range(emb_arr.shape[1])])\n",
    "emb_df[\"url\"] = img_df[\"url\"].values\n",
    "emb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dce6ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000, 2061)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge features back to train/test\n",
    "train_feat = train.merge(img_df, left_on=\"image_link\", right_on=\"url\", how=\"left\")\n",
    "train_feat = train_feat.merge(emb_df, left_on=\"image_link\", right_on=\"url\", how=\"left\")\n",
    "# fill numeric\n",
    "num_cols = [\"ipq_num\", \"width\", \"height\", \"mean_px\"] + [\n",
    "    c for c in train_feat.columns if c.startswith(\"emb_\")\n",
    "]\n",
    "for c in num_cols:\n",
    "    if c in train_feat:\n",
    "        train_feat[c] = train_feat[c].fillna(-1)\n",
    "\n",
    "train_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d73285d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.698096\n",
      "[400]\tvalid_0's rmse: 0.691454\n",
      "[600]\tvalid_0's rmse: 0.691162\n",
      "Early stopping, best iteration is:\n",
      "[511]\tvalid_0's rmse: 0.690949\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.68189\n",
      "[400]\tvalid_0's rmse: 0.676292\n",
      "[600]\tvalid_0's rmse: 0.67613\n",
      "Early stopping, best iteration is:\n",
      "[504]\tvalid_0's rmse: 0.675751\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.685319\n",
      "[400]\tvalid_0's rmse: 0.68121\n",
      "Early stopping, best iteration is:\n",
      "[345]\tvalid_0's rmse: 0.681003\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.677954\n",
      "[400]\tvalid_0's rmse: 0.674321\n",
      "Early stopping, best iteration is:\n",
      "[493]\tvalid_0's rmse: 0.674219\n",
      "Fold 5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.692652\n",
      "[400]\tvalid_0's rmse: 0.688222\n",
      "Early stopping, best iteration is:\n",
      "[432]\tvalid_0's rmse: 0.687927\n",
      "CV SMAPE: 51.84626451920001\n",
      "Saved submission to /Users/harshilpatel/CODE/test_out_full.csv\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import hstack, csr_matrix\n",
    "import lightgbm as lgb\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# prepare matrices (unchanged)\n",
    "num_cols = [\n",
    "    c\n",
    "    for c in train_feat.columns\n",
    "    if c in [\"ipq_num\", \"width\", \"height\", \"mean_px\"] or c.startswith(\"emb_\")\n",
    "]\n",
    "X_num = train_feat[num_cols].values\n",
    "X_num_test = test.merge(img_df, left_on=\"image_link\", right_on=\"url\", how=\"left\").merge(\n",
    "    emb_df, left_on=\"image_link\", right_on=\"url\", how=\"left\"\n",
    ")\n",
    "X_num_test = (\n",
    "    X_num_test[[c for c in X_num_test.columns if c in num_cols]].fillna(-1).values\n",
    ")\n",
    "\n",
    "X_sparse = hstack([X_text_train, csr_matrix(X_num)])\n",
    "X_sparse_test = hstack([X_text_test, csr_matrix(X_num_test)])\n",
    "\n",
    "# target\n",
    "y = train_feat[\"price\"].values\n",
    "\n",
    "# log transform\n",
    "y_log = np.log1p(y)\n",
    "\n",
    "# CV\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "pred_oof = np.zeros(len(y))\n",
    "pred_test = np.zeros(X_sparse_test.shape[0])\n",
    "\n",
    "for fold, (tr, val) in enumerate(kf.split(X_sparse)):\n",
    "    print(\"Fold\", fold + 1)\n",
    "    train_set = lgb.Dataset(X_sparse[tr], y_log[tr])\n",
    "    val_set = lgb.Dataset(X_sparse[val], y_log[val])\n",
    "    params = {\n",
    "        \"objective\": \"regression\",\n",
    "        \"metric\": \"rmse\",\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"num_leaves\": 128,\n",
    "        \"verbosity\": -1,\n",
    "    }\n",
    "\n",
    "    # use callback-based early stopping and logging\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_set,\n",
    "        num_boost_round=2000,\n",
    "        valid_sets=[val_set],\n",
    "        callbacks=[early_stopping(stopping_rounds=100), log_evaluation(period=200)],\n",
    "    )\n",
    "\n",
    "    # safe selection of iteration to use for predict\n",
    "    n_iter = getattr(model, \"best_iteration\", None)\n",
    "    if n_iter is None or n_iter == 0:\n",
    "        n_iter = model.num_trees()\n",
    "\n",
    "    pred_oof[val] = np.expm1(model.predict(X_sparse[val], num_iteration=n_iter))\n",
    "    pred_test += (\n",
    "        np.expm1(model.predict(X_sparse_test, num_iteration=n_iter)) / kf.n_splits\n",
    "    )\n",
    "\n",
    "\n",
    "# SMAPE\n",
    "def smape(y_true, y_pred):\n",
    "    denom = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
    "    denom[denom == 0] = 1e-6\n",
    "    return np.mean(np.abs(y_true - y_pred) / denom) * 100\n",
    "\n",
    "\n",
    "print(\"CV SMAPE:\", smape(y, pred_oof))\n",
    "\n",
    "# Save submission\n",
    "out = pd.DataFrame(\n",
    "    {\"sample_id\": test[\"sample_id\"], \"price\": np.clip(pred_test, 0.01, None)}\n",
    ")\n",
    "out.to_csv(OUTPUT_SUBMISSION, index=False)\n",
    "print(\"Saved submission to\", OUTPUT_SUBMISSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f6a6e0",
   "metadata": {},
   "source": [
    "## Methodology (one-page)\n",
    "\n",
    "The notebook will produce a one-page markdown `methodology_one_page.md` describing dataset, preprocessing, modeling, and improvements. Edit as needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7bf3557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "FINAL PARAMETERS AND METRICS SUMMARY\n",
      "==================================================\n",
      "\n",
      "--- DATA PATHS ---\n",
      "ZIP_PATH: /Users/harshilpatel/CODE/Student Resource.zip\n",
      "EXTRACT_DIR: /Users/harshilpatel/CODE/student_resource_extracted\n",
      "OUTPUT_SUBMISSION: /Users/harshilpatel/CODE/test_out_full.csv\n",
      "\n",
      "--- FEATURE ENGINEERING PARAMETERS ---\n",
      "IMAGE_SAMPLE_LIMIT: 2000\n",
      "TFIDF_MAX_FEATURES: 10000\n",
      "TEXT FEATURES SHAPE: (75000, 10000)\n",
      "IMAGE DIR: /Users/harshilpatel/CODE/student_resource_extracted/images\n",
      "NUMERICAL FEATURES: 2051 features\n",
      "\n",
      "--- MODEL PARAMETERS ---\n",
      "MODEL: LightGBM\n",
      "OBJECTIVE: regression\n",
      "METRIC: rmse\n",
      "LEARNING RATE: 0.05\n",
      "NUM_LEAVES: 128\n",
      "NUM_BOOST_ROUNDS: 2000\n",
      "EARLY_STOPPING_ROUNDS: 100\n",
      "\n",
      "--- CROSS-VALIDATION PARAMETERS ---\n",
      "CV METHOD: KFold\n",
      "N_SPLITS: 5\n",
      "SHUFFLE: True\n",
      "RANDOM_STATE: 42\n",
      "\n",
      "--- EVALUATION METRICS ---\n",
      "MSE: 746.014998\n",
      "RMSE: 27.313275\n",
      "SMAPE: 51.846265\n",
      "\n",
      "--- TRANSFORMATION ---\n",
      "TARGET TRANSFORMATION: Log(1+y)\n",
      "PREDICTION TRANSFORMATION: exp(pred)-1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Calculate additional metrics\n",
    "mse = mean_squared_error(y, pred_oof)\n",
    "rmse = np.sqrt(mse)\n",
    "smape_score = smape(y, pred_oof)  # Already calculated in previous cell\n",
    "\n",
    "# Print all final parameters and metrics\n",
    "print(\"=\" * 50)\n",
    "print(\"FINAL PARAMETERS AND METRICS SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\\n--- DATA PATHS ---\")\n",
    "print(f\"ZIP_PATH: {ZIP_PATH}\")\n",
    "print(f\"EXTRACT_DIR: {EXTRACT_DIR}\")\n",
    "print(f\"OUTPUT_SUBMISSION: {OUTPUT_SUBMISSION}\")\n",
    "\n",
    "print(\"\\n--- FEATURE ENGINEERING PARAMETERS ---\")\n",
    "print(f\"IMAGE_SAMPLE_LIMIT: {IMAGE_SAMPLE_LIMIT}\")\n",
    "print(f\"TFIDF_MAX_FEATURES: {TFIDF_MAX_FEATURES}\")\n",
    "print(f\"TEXT FEATURES SHAPE: {X_text_train.shape}\")\n",
    "print(f\"IMAGE DIR: {IMG_DIR}\")\n",
    "print(\n",
    "    f\"NUMERICAL FEATURES: {', '.join(num_cols) if len(num_cols) < 10 else f'{len(num_cols)} features'}\"\n",
    ")\n",
    "\n",
    "print(\"\\n--- MODEL PARAMETERS ---\")\n",
    "print(f\"MODEL: LightGBM\")\n",
    "print(f\"OBJECTIVE: {params['objective']}\")\n",
    "print(f\"METRIC: {params['metric']}\")\n",
    "print(f\"LEARNING RATE: {params['learning_rate']}\")\n",
    "print(f\"NUM_LEAVES: {params['num_leaves']}\")\n",
    "print(f\"NUM_BOOST_ROUNDS: 2000\")\n",
    "print(f\"EARLY_STOPPING_ROUNDS: 100\")\n",
    "\n",
    "print(\"\\n--- CROSS-VALIDATION PARAMETERS ---\")\n",
    "print(f\"CV METHOD: KFold\")\n",
    "print(f\"N_SPLITS: {kf.n_splits}\")\n",
    "print(f\"SHUFFLE: {kf.shuffle}\")\n",
    "print(f\"RANDOM_STATE: {kf.random_state}\")\n",
    "\n",
    "print(\"\\n--- EVALUATION METRICS ---\")\n",
    "print(f\"MSE: {mse:.6f}\")\n",
    "print(f\"RMSE: {rmse:.6f}\")\n",
    "print(f\"SMAPE: {smape_score:.6f}\")\n",
    "\n",
    "print(\"\\n--- TRANSFORMATION ---\")\n",
    "print(f\"TARGET TRANSFORMATION: Log(1+y)\")\n",
    "print(f\"PREDICTION TRANSFORMATION: exp(pred)-1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-1 (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
